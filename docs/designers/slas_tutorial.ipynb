{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98936916-e046-4f12-a8b3-00eeb32db431",
   "metadata": {},
   "source": [
    "# Single level adaptive sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8920e2b4-50ae-429b-9a46-be9cc2d077c3",
   "metadata": {},
   "source": [
    "## Example setup\n",
    "\n",
    "We'll create an experimental design for the following toy simulator function on a\n",
    "2-dimensional input space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a5158c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from exauq.core.modelling import SimulatorDomain\n",
    "\n",
    "\n",
    "domain = SimulatorDomain([(0, 1), (0, 1)])\n",
    "\n",
    "def simulation_func(x: np.ndarray) -> float:\n",
    "    return x[1] + x[0]**2 + x[1]**2 - np.sqrt(2) + np.sin(2 * np.pi * x[0]) + np.sin(4 * np.pi * x[0] * x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cde300",
   "metadata": {},
   "source": [
    "\n",
    "Make some randomly-generated simulator inputs and calculated outputs, as an initial design.\n",
    "We'll use a Latin hypercube sampling, as provided by [scipy](https://scipy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b9ffff7-53fc-4bfd-9d13-347a671a9475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.qmc import LatinHypercube\n",
    "from exauq.core.modelling import TrainingDatum\n",
    "\n",
    "\n",
    "sampler = LatinHypercube(domain.dim)\n",
    "initial_design_arr = sampler.random(n=10)  # will sample in the unit cube, which is what we want in this case\n",
    "initial_outputs = np.array([simulation_func(x) for x in initial_design_arr])\n",
    "initial_data = TrainingDatum.list_from_arrays(initial_design_arr, initial_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a6814-b534-4cc4-ad2e-8e8d163eb011",
   "metadata": {},
   "source": [
    "## Set up GP with initial design\n",
    "\n",
    "Next we'll train a GP. We first create a new GP using the `MogpEmulator` class, specifying that it uses a Matern 5/2 kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d03cf9ea-1d7c-4947-8d22-a49e645694aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too few unique inputs; defaulting to flat priors\n",
      "Too few unique inputs; defaulting to flat priors\n"
     ]
    }
   ],
   "source": [
    "from exauq.core.emulators import MogpEmulator\n",
    "\n",
    "# Don't display warnings from mogp-emulator\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "gp = MogpEmulator(kernel=\"Matern52\")\n",
    "gp.fit(initial_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fbc85d-bd80-44bc-9ce2-79eda139a79d",
   "metadata": {},
   "source": [
    "## Find new design points using leave-one-out adaptive sampling\n",
    "\n",
    "Let's now find a new design point using the leave-one-out adaptive design methodology. We\n",
    "use the function `compute_single_level_loo_samples` to do this. This function requires two\n",
    "arguments:\n",
    "- The GP to find the new design point for.\n",
    "- The `SimulatorDomain` object defining the input space on which the simulator inputs are\n",
    "  defined.\n",
    "\n",
    "By default, a single, new design point will be calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21059bd1-e419-47f1-b51f-9366c249a0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Input(np.float64(0.4958093479799048), np.float64(7.637374342395198e-07))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from exauq.core.designers import compute_single_level_loo_samples\n",
    "\n",
    "new_design_pts = compute_single_level_loo_samples(gp, domain)\n",
    "new_design_pts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7b1da5-0ad8-40a7-bceb-723d26e197a8",
   "metadata": {},
   "source": [
    "If instead we want to compute a batch of training inputs in one go, we can do this by\n",
    "specifying a different batch size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fda4a52c-b333-4b6b-94b4-45e909b3f6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Input(np.float64(0.4958715961234705), np.float64(2.5514364121459465e-08)),\n",
       " Input(np.float64(0.9999966883166532), np.float64(0.5447807986743418)),\n",
       " Input(np.float64(3.581779252082029e-07), np.float64(0.3680394329137556)),\n",
       " Input(np.float64(0.6047052623895744), np.float64(1.9163934035504315e-05)),\n",
       " Input(np.float64(0.2681917022018456), np.float64(0.9999953585128315)))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_design_pts = compute_single_level_loo_samples(gp, domain, batch_size=5)\n",
    "new_design_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a0bd5e-037d-4710-99a3-8c3309f4a234",
   "metadata": {},
   "source": [
    "Note how the new design points all lie within the simulator domain we defined earlier,\n",
    "i.e. they all lie in the unit square.\n",
    "\n",
    "The final step is to update the GP using the newly-calculated design points. This first\n",
    "requires us to compute the simulator values at the design points (in our case, using the\n",
    "toy function defined earlier):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "98b05590",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_outputs = [simulation_func(x) for x in new_design_pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330022ae",
   "metadata": {},
   "source": [
    "To update the GP, we combine the old training data with the new input/outputs calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a83fa641",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = [TrainingDatum(x, y) for x, y in zip(new_design_pts, new_outputs)]\n",
    "training_data = list(gp.training_data) + new_data\n",
    "gp.fit(training_data)\n",
    "\n",
    "# Sense-check that the updated GP now has the combined data\n",
    "assert(len(gp.training_data) == len(initial_data) + len(new_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc7c696",
   "metadata": {},
   "source": [
    "## Using a different GP for leave-one-out sampling methodology\n",
    "\n",
    "By default, the leave-one-out errors GP calculated during the adaptive sampling method\n",
    "uses a fresh copy of the supplied GP. In particular, it will use the same kernel function\n",
    "as the original. We can instead specify that a different GP is used by supplying a new one\n",
    "with the settings we desire. For example, to ensure that the leave-one-out errors GP uses\n",
    "a squared exponential kernel instead of a Matern 5/2, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ce5e2a62-eeab-49ac-9889-d1bacfd14c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too few unique inputs; defaulting to flat priors\n",
      "Too few unique inputs; defaulting to flat priors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Input(np.float64(0.7903157291293377), np.float64(0.7431890062662102)),\n",
       " Input(np.float64(0.7580092915972919), np.float64(0.9999999457736009)))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqexp_gp = MogpEmulator(kernel=\"SquaredExponential\")\n",
    "new_design_pts2 = compute_single_level_loo_samples(gp, domain, batch_size=2, loo_errors_gp=sqexp_gp)\n",
    "new_design_pts2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
