{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98936916-e046-4f12-a8b3-00eeb32db431",
   "metadata": {},
   "source": [
    "# Single Level Adaptive Sampling\n",
    "\n",
    "This tutorial will show you how to extend an initial experimental design for a Gaussian\n",
    "process (GP) emulator, using an adaptive sampling technique. The idea is to take our\n",
    "current GP and find a new design point (or batch or points) that will have 'the greatest\n",
    "impact' on improving the fit of the GP.\n",
    "\n",
    "This tutorial will show you how to:\n",
    "\n",
    "* Use the function `compute_single_level_loo_samples` from the `exauq.core.designers`\n",
    "  module to extend an initial experimental design with a new design point (or batch of\n",
    "  new design points).\n",
    "* How to repeatedly add new design points using this method.\n",
    "\n",
    "If you are unfamiliar with how to train a GP using the EXAUQ-Toolbox, you may want to\n",
    "first work through the tutorial, [Training A Gaussian Process Emulator](./training_gp_tutorial.ipynb).\n",
    "\n",
    "<div class=\"admonition note\">\n",
    "    <p class=\"admonition-title\">Note</p>\n",
    "    <p>\n",
    "        The function <code>compute_single_level_loo_samples</code> implements the\n",
    "        cross-validation-based adaptive sampling for GPs, as described in\n",
    "        Mohammadi, H. et al. (2022) \"Cross-Validation-based Adaptive Sampling for Gaussian process models\". DOI:\n",
    "        <a href=\"https://doi.org/10.1137/21M1404260\">https://doi.org/10.1137/21M1404260</a>.\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "We'll work with the same toy simulator function found in the tutorial,\n",
    "[Training A Gaussian Process Emulator](./training_gp_tutorial.ipynb). This is the function\n",
    "$$\n",
    "f(x_1, x_2) = x_2 + x_1^2 + x_2^2 - \\sqrt{2} + \\mathrm{sin}(2\\pi x_1) + \\mathrm{sin}(4\\pi x_1 x_2)\n",
    "$$\n",
    "with simulator domain defined as the rectangle $\\mathcal{D}$ consisting of points\n",
    "$(x_1, x_2)$ where $-1 \\leq x_1 \\leq 1$ and $1 \\leq x_2 \\leq 100$. We can express this in\n",
    "code as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7237ad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exauq.core.modelling import SimulatorDomain, Input\n",
    "import numpy as np\n",
    "\n",
    "# The bounds define the lower and upper bounds on each coordinate\n",
    "domain = SimulatorDomain(bounds=[(-1, 1), (1, 100)])\n",
    "\n",
    "def sim_func(x: Input) -> float:\n",
    "    return (\n",
    "        x[1] + x[0]**2 + x[1]**2 - np.sqrt(2)\n",
    "        + np.sin(2 * np.pi * x[0]) + np.sin(4 * np.pi * x[0] * x[1])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f3eaf4",
   "metadata": {},
   "source": [
    "## Initial design\n",
    "\n",
    "To perform adaptive sampling, we need to begin with a Gaussian process (GP) emulator\n",
    "trained with an initial design. We'll do this by using a Latin hypercube design (with the\n",
    "aid of [scipy](https://scipy.org/)) and using a GP with a Matern 5/2 kernel. The approach below is a condensed version of that found in the tutorial\n",
    "[Training A Gaussian Process Emulator](./training_gp_tutorial.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a5158c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too few unique inputs; defaulting to flat priors\n",
      "Too few unique inputs; defaulting to flat priors\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats.qmc import LatinHypercube\n",
    "from exauq.core.modelling import TrainingDatum\n",
    "from exauq.core.emulators import MogpEmulator\n",
    "\n",
    "\n",
    "# Create Latin hypercube sample, setting a seed to make the sampling repeatable.\n",
    "sampler = LatinHypercube(domain.dim, seed=1)\n",
    "lhs_array = sampler.random(n=20)\n",
    "\n",
    "# Scale the samples from the unit square to Input objects that are contained in the\n",
    "# domain.\n",
    "lhs_inputs = [domain.scale(row) for row in lhs_array]\n",
    "\n",
    "# Calculate simulator outputs, using our toy simulator function.\n",
    "outputs = [sim_func(x) for x in lhs_inputs]\n",
    "\n",
    "# Create the training data of input/output pairs.\n",
    "data = [TrainingDatum(x, y) for x, y in zip(lhs_inputs, outputs)]\n",
    "\n",
    "# Define a GP with a Matern 5/2 kernel and fit to the data.\n",
    "gp = MogpEmulator(kernel=\"Matern52\")\n",
    "gp.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbca761",
   "metadata": {},
   "source": [
    "(The messages printed are from the `mogp_emulator` package and can be ignored: they\n",
    "arise when initialising a new GP due to the face that it hasn't been trained on any data.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fbc85d-bd80-44bc-9ce2-79eda139a79d",
   "metadata": {},
   "source": [
    "## Extend the design using leave-one-out adaptive sampling\n",
    "\n",
    "Let's now find a new design point using the leave-one-out adaptive design methodology. The\n",
    "idea is to take our current GP and find a new design point (or batch or points) that will\n",
    "have 'the greatest impact' on improving the fit of the GP, when combined with the\n",
    "corresponding simulator output (or outputs in the batch case). We use the function\n",
    "`compute_single_level_loo_samples` to do this. This function requires two arguments:\n",
    "\n",
    "- The GP to find the new design point for.\n",
    "- The `SimulatorDomain` describing the domain on which the simulator is defined.\n",
    "\n",
    "By default, a batch consisting of a single, new design point will be calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21059bd1-e419-47f1-b51f-9366c249a0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Input(np.float64(0.9123648084857612), np.float64(57.969585575716906))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from exauq.core.designers import compute_single_level_loo_samples\n",
    "\n",
    "# Suppress warnings that arise from mogp_emulator\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "new_design_pts = compute_single_level_loo_samples(gp, domain)\n",
    "new_design_pts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7b1da5-0ad8-40a7-bceb-723d26e197a8",
   "metadata": {},
   "source": [
    "If instead we want to compute multiple new design points in one go, we can do this by\n",
    "specifying a different batch size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fda4a52c-b333-4b6b-94b4-45e909b3f6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Input(np.float64(0.3121786431504767), np.float64(55.84731888607564)),\n",
       " Input(np.float64(-0.714369858819013), np.float64(56.467075523054405)),\n",
       " Input(np.float64(-0.7031285324472387), np.float64(52.94237232599945)),\n",
       " Input(np.float64(-0.6948171961040246), np.float64(54.291724400055024)),\n",
       " Input(np.float64(0.32094153495984545), np.float64(54.75773060166758)))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_design_pts = compute_single_level_loo_samples(gp, domain, batch_size=5)\n",
    "new_design_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a0bd5e-037d-4710-99a3-8c3309f4a234",
   "metadata": {},
   "source": [
    "Note how the new design points all lie within the simulator domain we defined earlier,\n",
    "i.e. they all lie in the rectangle $\\mathcal{D}$.\n",
    "\n",
    "It's worth pointing out that these design points are not equal to any of the training inputs\n",
    "for the GP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1697db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_inputs = [datum.input for datum in gp.training_data]\n",
    "for x in new_design_pts:\n",
    "    assert not any(x == x_train for x_train in training_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4dfa10",
   "metadata": {},
   "source": [
    "## Update the GP\n",
    "\n",
    "The final step is to update the fit of the GP using the newly-calculated design points.\n",
    "This first requires us to compute the simulator values at the design points (in our case,\n",
    "using the toy function defined earlier) in order to create new training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98b05590",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_outputs = [sim_func(x) for x in new_design_pts]\n",
    "new_data = [TrainingDatum(x, y) for x, y in zip(new_design_pts, new_outputs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330022ae",
   "metadata": {},
   "source": [
    "To update the GP, we fit it with both the old and new training data combined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a83fa641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data: 25\n"
     ]
    }
   ],
   "source": [
    "# gp.training_data is a tuple, so make a list to extend\n",
    "# with the new data\n",
    "data = list(gp.training_data) + new_data\n",
    "gp.fit(data)\n",
    "\n",
    "# Sense-check that the updated GP now has the combined data\n",
    "print(\"Number of training data:\", len(gp.training_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741c8aa6",
   "metadata": {},
   "source": [
    "This completes one adaptive sampling 'iteration'. It's important to note that, when\n",
    "creating a batch of multiple new design points, the fit of the GP is not updated between\n",
    "the creation of each new point in the batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9121e9a9",
   "metadata": {},
   "source": [
    "## Repeated application\n",
    "\n",
    "In general, we can perform multiple adaptive sampling iterations to further improve the\n",
    "fit of the GP with newly sampled design point(s). The following code goes through five\n",
    "more sampling iterations, producing a single new design point at each iteration. We have\n",
    "also introduced a helper function to assist in retraining the GP. (Once again, the\n",
    "messages printed are from the `mogp_emulator` package and can be ignored.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2457caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n",
      "Prior solver failed to converge\n"
     ]
    }
   ],
   "source": [
    "def update_gp(gp, additional_data):\n",
    "    \"\"\"Updates the fit of the supplied GP with additional training data.\"\"\"\n",
    "\n",
    "    # gp.training_data is a tuple, so make a list to extend\n",
    "    # with the new data\n",
    "    data = list(gp.training_data) + additional_data\n",
    "    gp.fit(data)\n",
    "\n",
    "for i in range(5):\n",
    "    # Find new design point adaptively (via batch of length 1)\n",
    "    x = compute_single_level_loo_samples(gp, domain)[0]\n",
    "    \n",
    "    # Compute simulator output at new design point\n",
    "    y = sim_func(x)\n",
    "\n",
    "    # Update GP fit\n",
    "    new_data = [TrainingDatum(x, y)]\n",
    "    update_gp(gp, new_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
