{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Multi-Level Gaussian Process Emulator\n",
    "\n",
    "The purpose of this tutorial is to demonstrate how to train a multi-level Gaussian process\n",
    "(GP) to emulate a simulator. It uses the same example simulator from the tutorial\n",
    "[Training a Gaussian Process Emulator](./training_gp_tutorial.md), which demonstrates\n",
    "training a GP in the classical, non-levelled paradigm; you may wish to work through that\n",
    "tutorial first if you haven't done so already.\n",
    "\n",
    "This tutorial will show you how to:\n",
    "\n",
    "* Work with multi-level objects (such as training data) using the\n",
    "  [`MultiLevel`][exauq.core.modelling.MultiLevel] class.\n",
    "* Create training data for a multi-level emulation scenario.\n",
    "* Define and train a multi-level Gaussian process.\n",
    "* Make new predictions of simulator outputs using the trained multi-level GP.\n",
    "\n",
    "!!! note\n",
    "    \n",
    "    Due to the pseudo-stochastic nature of the algorithms for fitting\n",
    "    Gaussian processes, you may get slight differences in some of the code outputs in\n",
    "    this tutorial.\n",
    "\n",
    "## A toy multi-level simulator\n",
    "\n",
    "This tutorial will look at taking a multi-level approach to emulating the toy simulator\n",
    "found in the tutorial,\n",
    "[Training A Gaussian Process Emulator](./training_gp_tutorial.md).\n",
    "This is defined to be the mathematical function\n",
    "$$\n",
    "f_2(x_1, x_2) = x_2 + x_1^2 + x_2^2 - \\sqrt{2} + \\mathrm{sin}(2\\pi x_1) \\\n",
    "+ \\mathrm{sin}(4\\pi x_1 x_2)\n",
    "$$\n",
    "defined on the rectangular domain $\\mathcal{D}$ consisting of 2d points\n",
    "$(x_1, x_2)$, where $0 \\leq x_1 \\leq 1$ and $-0.5 \\leq x_2 \\leq 1.5$.\n",
    "\n",
    "We will consider this as the top level of a multi-level simulator of two levels. The level\n",
    "1 version is a simpler function, which is typically cheaper to run than the top level simulator. \n",
    "$$\n",
    "f_1(x_1, x_2) = x_2 + x_1^2 + x_2^2 - \\sqrt{2} \\\\\n",
    "$$\n",
    "In the multi-level paradigm, the idea is to emulate the top level simulator $f_2$ with a\n",
    "multi-level GP, in this case having two levels. The multi-level GP is\n",
    "a sum of two GPs, one at each level. The GP at the first level emulates\n",
    "the level 1 function $f_1$, while the second level GP emulates the **difference** between\n",
    "the second and first level simulators:\n",
    "$$\n",
    "\\delta(x_1, x_2) = f_2(x_1, x_2) - f_1(x_1, x_2) = \\mathrm{sin}(2\\pi x_1) + \\mathrm{sin}(4\\pi x_1 x_2)\n",
    "$$\n",
    "We take this delta because the difference between the levels is often a simpler function than the top level itself.\n",
    "\n",
    "!!! note\n",
    "\n",
    "    The multi-level GP approach that we are taking is an autoregressive approach to decompose the top level into the sum of the lower level \n",
    "    plus the difference between the two levels as described in Kennedy, Marc & O'Hagan, A. (1998) \"Predicting the Output from a Complex Computer Code When Fast Approximations Are Available\". \n",
    "    DOI:<https://doi.org/10.1093/biomet/87.1.1>\n",
    "\n",
    "We express all this in code as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exauq.core.modelling import SimulatorDomain, Input\n",
    "import numpy as np\n",
    "\n",
    "# The bounds define the lower and upper bounds on each coordinate\n",
    "domain = SimulatorDomain(bounds=[(0, 1), (-0.5, 1.5)])\n",
    "\n",
    "# The full simulator (at level 2)\n",
    "def sim_level2(x: Input) -> float:\n",
    "    return (\n",
    "        x[1] + x[0]**2 + x[1]**2 - np.sqrt(2)\n",
    "        + np.sin(2 * np.pi * x[0]) + np.sin(4 * np.pi * x[0] * x[1])\n",
    "    )\n",
    "\n",
    "# The level 1 simulator\n",
    "def sim_level1(x: Input) -> float:\n",
    "    return x[1] + x[0]**2 + x[1]**2 - np.sqrt(2)\n",
    "\n",
    "# The difference between levels 1 and 2\n",
    "def sim_delta(x: Input) -> float:\n",
    "    return sim_level2(x) - sim_level1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-level objects\n",
    "\n",
    "In order to help structure objects in the multi-level paradigm, the EXAUQ-Toolbox provides\n",
    "the [`MultiLevel`][exauq.core.modelling.MultiLevel] class. This is like a dictionary,\n",
    "except that the keys are integers representing the levels. For example, we can create a\n",
    "multi-level collection of floating point numbers, for 3 levels, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 1 value: 1.1\n",
      "Level 2 value: 2.2\n",
      "Level 3 value: 3.3\n"
     ]
    }
   ],
   "source": [
    "from exauq.core.modelling import MultiLevel\n",
    "\n",
    "# Creates floating point numbers at levels 1, 2 and 3\n",
    "ml_numbers = MultiLevel([1.1, 2.2, 3.3])\n",
    "\n",
    "# Get the numbers for each level using dictionary access notation []\n",
    "print(\"Level 1 value:\", ml_numbers[1])\n",
    "print(\"Level 2 value:\", ml_numbers[2])\n",
    "print(\"Level 3 value:\", ml_numbers[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, providing a sequence of length `n` to\n",
    "[`MultiLevel`][exauq.core.modelling.MultiLevel] will assign the list elements to the\n",
    "levels `1, 2, ..., n` in order.\n",
    "\n",
    "We can get the levels in a multi-level collection by using the\n",
    "[`levels`][exauq.core.modelling.MultiLevel.levels] property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_numbers.levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an application, let's use the [`MultiLevel`][exauq.core.modelling.MultiLevel] class to\n",
    "encapsulate the different levels of our simulator, which will make our code a little\n",
    "neater later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_simulator = MultiLevel([sim_level1, sim_delta])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating multi-level training data\n",
    "\n",
    "The setup for doing multi-level emulation is similar to the\n",
    "[single level case](./training_gp_tutorial.md), with the exception that we work with\n",
    "multi-level objects. We need to construct some multi-level training data, utilising\n",
    "experimental designs for each level's simulator, then train a multi-level GP with this\n",
    "data.\n",
    "\n",
    "To create the training data, we'll use a Latin hypercube designer [`oneshot_lhs`][exauq.core.designers.oneshot_lhs] (with the aid of\n",
    "[scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.qmc.LatinHypercube.html)) at each level. (For more detailed explanation of creating an\n",
    "experimental design from a Latin hypercube sample, see the section,\n",
    "**Creating an experimental design** from the\n",
    "[Training a Gaussian Process Emulator](./training_gp_tutorial.md) tutorial.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exauq.core.designers import oneshot_lhs\n",
    "from exauq.core.modelling import MultiLevel, TrainingDatum\n",
    "\n",
    "# Create level 1 experimental design of 20 data points\n",
    "lhs_inputs1 = oneshot_lhs(domain, 20, seed=1)\n",
    "\n",
    "# Create level 2 experimental design of 5 data points\n",
    "lhs_inputs2 = oneshot_lhs(domain, 5, seed=1)\n",
    "\n",
    "# Put into a multi-level object\n",
    "design = MultiLevel([lhs_inputs1, lhs_inputs2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we calculate the simulator outputs and create the training data, doing this for\n",
    "each level separately. Note how we use the multi-level object of simulator functions we\n",
    "created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create level 1 simulator outputs and training data\n",
    "outputs1 = [ml_simulator[1](x) for x in design[1]]\n",
    "data1 = [TrainingDatum(x, y) for x, y in zip(design[1], outputs1)]\n",
    "\n",
    "# Create level 2 simulator outputs and training data\n",
    "outputs2 = [ml_simulator[2](x) for x in design[2]]\n",
    "data2 = [TrainingDatum(x, y) for x, y in zip(design[2], outputs2)]\n",
    "\n",
    "# Combine into a multi-level object\n",
    "training_data = MultiLevel([data1, data2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! note\n",
    "    \n",
    "    It is worth noting here for clarity that delta is calculated by `lhs_inputs2` being run through both level 1 and level 2 (see `sim_delta` function) to  make a single training point for delta. \n",
    "    These points run through level 1 for calculating this delta are **not** automatically included in the training data for the level 1 GP.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wish, we can verify that we have the correct data at each level by doing some\n",
    "manual inspections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of level 1 training data: 20\n",
      "Number of level 2 training data: 5\n",
      "\n",
      "Level 1:\n",
      "Inputs:                                 Output:             \n",
      "------------------------------------------------------------\n",
      "0.2744089188        1.0049536304        0.6759721219        \n",
      "0.5927920194        -0.3948649447       -1.3017578043       \n",
      "\n",
      "Level 2:\n",
      "Inputs:                                 Output:             \n",
      "------------------------------------------------------------\n",
      "0.2976356751        1.1198145215        0.0897465476        \n",
      "0.7711680775        0.7205402211        -0.3473985727       \n"
     ]
    }
   ],
   "source": [
    "print(\"Number of level 1 training data:\", len(training_data[1]))\n",
    "print(\"Number of level 2 training data:\", len(training_data[2]))\n",
    "\n",
    "# Show the first couple of data points for each level:\n",
    "print(\"\\nLevel 1:\")\n",
    "TrainingDatum.tabulate(training_data[1], rows = 2)\n",
    "\n",
    "print(\"\\nLevel 2:\")\n",
    "TrainingDatum.tabulate(training_data[2], rows = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining and fitting a multi-level GP\n",
    "\n",
    "Next, we need to define a multi-level GP with two levels, which we can do using the\n",
    "[`MultiLevelGaussianProcess`][exauq.core.modelling.MultiLevelGaussianProcess] class.\n",
    "To construct it, we need to create GPs for each level, which we'll do using the\n",
    "[`MogpEmulator`][exauq.core.emulators.MogpEmulator] class, with a Matern 5/2 kernel for\n",
    "each level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exauq.core.emulators import MogpEmulator\n",
    "from exauq.core.modelling import MultiLevelGaussianProcess\n",
    "\n",
    "gp1 = MogpEmulator(kernel=\"Matern52\")\n",
    "gp2 = MogpEmulator(kernel=\"Matern52\")\n",
    "\n",
    "mlgp = MultiLevelGaussianProcess([gp1, gp2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with single-level GPs, we can verify that our multi-level GP hasn't yet been trained on\n",
    "data. Note that each level of the GP has its own training data, so the\n",
    "[`training_data`][exauq.core.modelling.MultiLevelGaussianProcess.training_data]\n",
    "property of the multi-level GP is a [`MultiLevel`][exauq.core.modelling.MultiLevel] object: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLevel({1: (), 2: ()})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlgp.training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we train the multi-level GP with the multi-level data we created earlier, using\n",
    "the [`fit`][exauq.core.modelling.MultiLevelGaussianProcess.fit] method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlgp.fit(training_data)\n",
    "\n",
    "# Verify that the data is as we expect\n",
    "assert len(mlgp.training_data[1]) == 20\n",
    "assert len(mlgp.training_data[2]) == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions with the multi-level GP\n",
    "\n",
    "To finish off, let's use our newly-trained multi-level GP to estimate the output of our\n",
    "top-level simulator at a new input. We make a prediction with the multi-level GP using the\n",
    "[`predict`][exauq.core.modelling.MultiLevelGaussianProcess.predict] method. As described\n",
    "in the tutorial, [Training a Gaussian Process Emulator](./training_gp_tutorial.md), the\n",
    "prediction consists of both the point estimate and a measure of the uncertainty of the\n",
    "prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianProcessPrediction(estimate=np.float64(2.428045984265471), variance=np.float64(0.4494867295843319), standard_deviation=0.6704377149178974)\n",
      "Point estimate: 2.428045984265471\n",
      "Variance of estimate: 0.4494867295843319\n",
      "Standard deviation of estimate: 0.6704377149178974\n"
     ]
    }
   ],
   "source": [
    "x = Input(0.5, 1.5)\n",
    "prediction = mlgp.predict(x)\n",
    "\n",
    "print(prediction)\n",
    "print(\"Point estimate:\", prediction.estimate)\n",
    "print(\"Variance of estimate:\", prediction.variance)\n",
    "print(\"Standard deviation of estimate:\", prediction.standard_deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well the prediction did against the true simulator value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: 2.428045984265471\n",
      "Actual simulator value: 2.5857864376269055\n",
      "Percentage error: 6.100289299459712\n"
     ]
    }
   ],
   "source": [
    "y = sim_level2(x)  # the true value\n",
    "pct_error = 100 * abs((prediction.estimate - y) / y)\n",
    "\n",
    "print(\"Predicted value:\", prediction.estimate)\n",
    "print(\"Actual simulator value:\", y)\n",
    "print(\"Percentage error:\", pct_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the non-levelled case, we can also calculate the normalised expected square error\n",
    "for the prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7080815293819185"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.nes_error(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exauq-U32eSCBI-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
