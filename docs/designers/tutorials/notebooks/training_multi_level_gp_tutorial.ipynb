{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Multi-Level Gaussian Process Emulator\n",
    "\n",
    "The purpose of this tutorial is to demonstrate how to train a multi-level Gaussian process\n",
    "(GP) to emulate a simulator. It uses the same example simulator from the tutorial\n",
    "[Training a Gaussian Process Emulator](./training_gp_tutorial.md), which demonstrates\n",
    "training a GP in the classical, non-levelled paradigm; you may wish to work through that\n",
    "tutorial first if you haven't done so already.\n",
    "\n",
    "This tutorial will show you how to:\n",
    "\n",
    "* Work with multi-level objects (such as training data) using the `MultiLevel`\n",
    "  class.\n",
    "* Create training data for a multi-level emulation scenario.\n",
    "* Define and train a multi-level Gaussian process.\n",
    "* Make new predictions of simulator outputs using the trained multi-level GP.\n",
    "\n",
    "<div class=\"admonition note\">\n",
    "    <p class=\"admonition-title\">Note</p>\n",
    "    <p>\n",
    "        Due to the pseudo-stochastic nature of the algorithms for fitting\n",
    "        Gaussian processes, you may get slight differences in some of the code outputs in\n",
    "        this tutorial.\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "## A toy multi-level simulator\n",
    "\n",
    "This tutorial will look at taking a multi-level approach to emulating the toy simulator\n",
    "found in the tutorial,\n",
    "[Training A Gaussian Process Emulator](./training_gp_tutorial.md).\n",
    "This is is defined to be the mathematical function\n",
    "$$\n",
    "f(x_1, x_2) = x_2 + x_1^2 + x_2^2 - \\sqrt{2} + \\mathrm{sin}(2\\pi x_1) \\\n",
    "+ \\mathrm{sin}(4\\pi x_1 x_2)\n",
    "$$\n",
    "defined on the rectangular domain $\\mathcal{D}$ consisting of 2d points\n",
    "$(x_1, x_2)$, where $-1 \\leq x_1 \\leq 1$ and $1 \\leq x_2 \\leq 100$.\n",
    "\n",
    "We will consider this as the top level of a multi-level simulator of two levels. The level\n",
    "1 version is the simpler function\n",
    "$$\n",
    "f_1(x_1, x_2) = x_2 + x_1^2 + x_2^2 - \\sqrt{2}\n",
    "$$\n",
    "In the multi-level paradigm, the idea is to emulate the whole simulator $f$ with a\n",
    "multi-level GP, in this case having two levels. The multi-level GP is\n",
    "itself essentially a sum of two GPs, one at each level. The GP at the first level emulates\n",
    "the level 1 function $f_1$, while the second level GP emulates the **difference** between\n",
    "the second and first level simulators:\n",
    "$$\n",
    "\\delta(x_1, x_2) = f(x_1, x_2) - f_1(x_1, x_2) = \\mathrm{sin}(2\\pi x_1) + \\mathrm{sin}(4\\pi x_1 x_2)\n",
    "$$\n",
    "The reason for taking the difference is so that the full simulator $f$ is the sum of $f_1$\n",
    "and $\\delta$, which allows us to emulate each function separately via a multi-level GP.\n",
    "\n",
    "We express all this in code as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exauq.core.modelling import SimulatorDomain, Input\n",
    "import numpy as np\n",
    "\n",
    "# The bounds define the lower and upper bounds on each coordinate\n",
    "domain = SimulatorDomain(bounds=[(-1, 1), (1, 100)])\n",
    "\n",
    "# The full simulator (at level 2)\n",
    "def sim_func(x: Input) -> float:\n",
    "    return (\n",
    "        x[1] + x[0]**2 + x[1]**2 - np.sqrt(2)\n",
    "        + np.sin(2 * np.pi * x[0]) + np.sin(4 * np.pi * x[0] * x[1])\n",
    "    )\n",
    "\n",
    "# The level 1 simulator\n",
    "def sim_level1(x: Input) -> float:\n",
    "    return x[1] + x[0]**2 + x[1]**2 - np.sqrt(2)\n",
    "\n",
    "# The difference between levels 1 and 2\n",
    "def sim_delta(x: Input) -> float:\n",
    "    return sim_func(x) - sim_level1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-level objects\n",
    "\n",
    "In order to help structure objects in the multi-level paradigm, the EXAUQ-Toolbox provides\n",
    "the `MultiLevel` class. This is like a dictionary, except that the keys are integers\n",
    "representing the levels. For example, we can create a multi-level collection of floating\n",
    "point numbers, for 3 levels, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 1 value: 1.1\n",
      "Level 2 value: 2.2\n",
      "Level 3 value: 3.3\n"
     ]
    }
   ],
   "source": [
    "from exauq.core.modelling import MultiLevel\n",
    "\n",
    "# Creates floating point numbers at levels 1, 2 and 3\n",
    "ml_numbers = MultiLevel([1.1, 2.2, 3.3])\n",
    "\n",
    "# Get the numbers for each level using dictionary access notation []\n",
    "print(\"Level 1 value:\", ml_numbers[1])\n",
    "print(\"Level 2 value:\", ml_numbers[2])\n",
    "print(\"Level 3 value:\", ml_numbers[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, providing a sequence of length `n` to `MultiLevel` will assign the list\n",
    "elements to the levels `1, 2, ..., n` in order.\n",
    "\n",
    "We can get the levels in a multi-level collection by using the `levels` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_numbers.levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an application, let's use the `MultiLevel` class to encapsulate the different levels of\n",
    "our simulator, which will make our code a little neater later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_simulator = MultiLevel([sim_level1, sim_delta])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating multi-level training data\n",
    "\n",
    "The setup for doing multi-level emulation is similar to the\n",
    "[single level case](./training_gp_tutorial.md), with the exception that we work with\n",
    "multi-level objects. We need to construct some multi-level training data, utilising\n",
    "experimental designs for each level's simulator, then train a multi-level GP with this\n",
    "data.\n",
    "\n",
    "To create the training data, we'll use a Latin hypercube design (with the aid of\n",
    "[scipy](https://scipy.org/)) at each level. (For more detailed explanation of creating an\n",
    "experimental design from a Latin hypercube sample, see the section,\n",
    "**Creating an experimental design** from the\n",
    "[Training a Gaussian Process Emulator](./training_gp_tutorial.md) tutorial.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.qmc import LatinHypercube\n",
    "from exauq.core.modelling import MultiLevel, TrainingDatum\n",
    "\n",
    "# Set seed for repeatability.\n",
    "sampler = LatinHypercube(domain.dim, seed=1)\n",
    "\n",
    "# Create level 1 experimental design of 20 data points\n",
    "lhs_array1 = sampler.random(n=20)\n",
    "lhs_inputs1 = [domain.scale(row) for row in lhs_array1]\n",
    "\n",
    "# Create level 2 experimental design of 5 data points\n",
    "lhs_array2 = sampler.random(n=5)\n",
    "lhs_inputs2 = [domain.scale(row) for row in lhs_array2]\n",
    "\n",
    "# Put into a multi-level object\n",
    "design = MultiLevel([lhs_inputs1, lhs_inputs2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we calculate the simulator outputs and create the training data, doing this for\n",
    "each level separately. Note how we use the multi-level object of simulator functions we\n",
    "created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create level 1 simulator outputs and training data\n",
    "outputs1 = [ml_simulator[1](x) for x in design[1]]\n",
    "data1 = [TrainingDatum(x, y) for x, y in zip(lhs_inputs1, outputs1)]\n",
    "\n",
    "# Create level 2 simulator outputs and training data\n",
    "outputs2 = [ml_simulator[2](x) for x in design[2]]\n",
    "data2 = [TrainingDatum(x, y) for x, y in zip(lhs_inputs2, outputs2)]\n",
    "\n",
    "# Combine into a multi-level object\n",
    "training_data = MultiLevel([data1, data2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wish, we can verify that we have the correct data at each level by doing some\n",
    "manual inspections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of level 1 training data: 20\n",
      "Number of level 2 training data: 5\n",
      "\n",
      "Level 1:\n",
      "TrainingDatum(input=Input(np.float64(-0.45118216247002574), np.float64(75.49520470318662)), output=np.float64(5773.8104896605955))\n",
      "TrainingDatum(input=Input(np.float64(0.18558403872803675), np.float64(6.204185236670643)), output=np.float64(43.31632756065012))\n",
      "\n",
      "Level 2:\n",
      "TrainingDatum(input=Input(np.float64(-0.6860872668651894), np.float64(8.14123867468156)), output=np.float64(0.04053108865750232))\n",
      "TrainingDatum(input=Input(np.float64(0.2779780667419962), np.float64(61.11931671766958)), output=np.float64(0.857129851613081))\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of level 1 training data:\", len(training_data[1]))\n",
    "print(\"Number of level 2 training data:\", len(training_data[2]))\n",
    "\n",
    "# Show the first couple of data points for each level:\n",
    "print(\"\\nLevel 1:\")\n",
    "print(repr(training_data[1][0]))\n",
    "print(repr(training_data[1][1]))\n",
    "\n",
    "print(\"\\nLevel 2:\")\n",
    "print(repr(training_data[2][0]))\n",
    "print(repr(training_data[2][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining and fitting a multi-level GP\n",
    "\n",
    "Next, we need to define a multi-level GP with two levels, which we can do using the `MultiLevelGaussianProcess` class. To construct it, we need to create GPs for each level,\n",
    "which we'll do using the `MogpEmulator` class, with a Matern 5/2 kernel for each level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too few unique inputs; defaulting to flat priors\n",
      "Too few unique inputs; defaulting to flat priors\n",
      "Too few unique inputs; defaulting to flat priors\n",
      "Too few unique inputs; defaulting to flat priors\n"
     ]
    }
   ],
   "source": [
    "from exauq.core.emulators import MogpEmulator\n",
    "from exauq.core.modelling import MultiLevelGaussianProcess\n",
    "\n",
    "gp1 = MogpEmulator(kernel=\"Matern52\")\n",
    "gp2 = MogpEmulator(kernel=\"Matern52\")\n",
    "\n",
    "mlgp = MultiLevelGaussianProcess([gp1, gp2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The messages printed are from the `mogp_emulator` package and can be ignored: they\n",
    "arise when initialising a new GP due to the fact that it hasn't been trained on any data.)\n",
    "\n",
    "As with ordinary GPs, we can verify that our multi-level GP hasn't yet been trained on\n",
    "data. Note that each level of the GP has its own training data, so the `training_data`\n",
    "property of the multi-level GP is a `MultiLevel` object: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLevel({1: (), 2: ()})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlgp.training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we train the multi-level GP with the multi-level data we created earlier, using\n",
    "the `fit` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlgp.fit(training_data)\n",
    "\n",
    "# Verify that the data is as we expect\n",
    "assert len(mlgp.training_data[1]) == 20\n",
    "assert len(mlgp.training_data[2]) == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions with the multi-level GP\n",
    "\n",
    "To finish off, let's use our newly-trained multi-level GP to estimate the output of our\n",
    "top-level simulator at a new input. We make a prediction with the multi-level GP using the\n",
    "`predict` method. As described in the tutorial, [Training a Gaussian Process\n",
    "Emulator](./training_gp_tutorial.md), the prediction consists of both the point\n",
    "estimate and a measure of the uncertainty of the prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianProcessPrediction(estimate=np.float64(2549.8545301180034), variance=np.float64(1.236147336654947), standard_deviation=1.1118216298736714)\n",
      "Point estimate: 2549.8545301180034\n",
      "Variance of estimate: 1.236147336654947\n",
      "Standard deviation of estimate: 1.1118216298736714\n"
     ]
    }
   ],
   "source": [
    "x = Input(0.5, 50)\n",
    "prediction = mlgp.predict(x)\n",
    "\n",
    "print(prediction)\n",
    "print(\"Point estimate:\", prediction.estimate)\n",
    "print(\"Variance of estimate:\", prediction.variance)\n",
    "print(\"Standard deviation of estimate:\", prediction.standard_deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well the prediction did against the true simulator value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: 2549.8545301180034\n",
      "Actual simulator value: 2548.835786437627\n",
      "Percentage error: 0.03996898057524886\n"
     ]
    }
   ],
   "source": [
    "y = sim_func(x)  # the true value\n",
    "pct_error = 100 * abs((prediction.estimate - y) / y)\n",
    "\n",
    "print(\"Predicted value:\", prediction.estimate)\n",
    "print(\"Actual simulator value:\", y)\n",
    "print(\"Percentage error:\", pct_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the non-levelled case, we can also calculate the normalised expected square error\n",
    "for the prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7947014462360164"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.nes_error(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
