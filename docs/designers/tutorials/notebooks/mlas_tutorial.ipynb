{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98936916-e046-4f12-a8b3-00eeb32db431",
   "metadata": {},
   "source": [
    "# Multi-Level Adaptive Sampling\n",
    "\n",
    "This tutorial will show you how to extend an initial experimental design for a multi-level\n",
    "Gaussian process (GP), using an adaptive sampling technique. Similarly to the\n",
    "[non-levelled / single level case](./slas_tutorial.md), the idea is to take our current\n",
    "multi-level GP and find a new design point (or batch of points) that will best\n",
    "improve the fit of the multi-level GP. In contrast to the single level case, we also need\n",
    "to determine the particular GP level for the new design point (or points), which\n",
    "determines the simulator run(s) required.\n",
    "\n",
    "This tutorial will show you how to:\n",
    "\n",
    "* Use the function\n",
    "  [`compute_multi_level_loo_samples`][exauq.core.designers.compute_multi_level_loo_samples]\n",
    "  to extend an initial experimental design with a new design point (or batch of\n",
    "  new design points), together with the level for the point(s).\n",
    "* How to repeatedly add new design points using this method.\n",
    "\n",
    "If you are unfamiliar with how to train a multi-level GP using the EXAUQ-Toolbox, you may\n",
    "want to first work through the tutorial,\n",
    "[Training a Multi-Level Gaussian Process Emulator](./training_multi_level_gp_tutorial.md). \n",
    "You may also wish to work through the\n",
    "[Single Level Adaptive Sampling](./slas_tutorial.md) tutorial, to familiarise yourself\n",
    "with adaptive sampling in the non-levelled case.\n",
    "\n",
    "!!! note\n",
    "\n",
    "    The function\n",
    "    [`compute_multi_level_loo_samples`][exauq.core.designers.compute_multi_level_loo_samples]\n",
    "    implements the cross-validation-based adaptive sampling for multi-level GPs described\n",
    "    in Kimpton, L. M. et al. (2023) \"Cross-Validation Based Adaptive Sampling for\n",
    "    Multi-Level Gaussian Process Models\". arXiv: <https://arxiv.org/abs/2307.09095>\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "We'll work with the same toy simulator function found in the tutorial,\n",
    "[Training a Multi-Level Gaussian Process Emulator](./training_multi_level_gp_tutorial.md). This is the function\n",
    "$$\n",
    "f(x_1, x_2) = x_2 + x_1^2 + x_2^2 - \\sqrt{2} + \\mathrm{sin}(2\\pi x_1) + \\mathrm{sin}(4\\pi x_1 x_2)\n",
    "$$\n",
    "with simulator domain defined as the rectangle $\\mathcal{D}$ consisting of points\n",
    "$(x_1, x_2)$ where $-1 \\leq x_1 \\leq 1$ and $1 \\leq x_2 \\leq 100$. We view this as the\n",
    "top level of a 2-level multi-level simulator, with level 1 being given by the simpler\n",
    "function\n",
    "$$\n",
    "f_1(x_1, x_2) = x_2 + x_1^2 + x_2^2 - \\sqrt{2}\n",
    "$$\n",
    "and the difference function between the levels being\n",
    "$$\n",
    "\\delta(x_1, x_2) = f(x_1, x_2) - f_1(x_1, x_2) = \\mathrm{sin}(2\\pi x_1) + \\mathrm{sin}(4\\pi x_1 x_2)\n",
    "$$\n",
    "As in the tutorial linked above, we will use a multi-level GP to emulate\n",
    "$f = f_1 + \\delta$.\n",
    "\n",
    "\n",
    "We can express this in code as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7237ad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exauq.core.modelling import SimulatorDomain, Input, MultiLevel\n",
    "import numpy as np\n",
    "\n",
    "# The bounds define the lower and upper bounds on each coordinate\n",
    "domain = SimulatorDomain(bounds=[(-1, 1), (1, 100)])\n",
    "\n",
    "# The full simulator (at level 2)\n",
    "def sim_func(x: Input) -> float:\n",
    "    return (\n",
    "        x[1] + x[0]**2 + x[1]**2 - np.sqrt(2)\n",
    "        + np.sin(2 * np.pi * x[0]) + np.sin(4 * np.pi * x[0] * x[1])\n",
    "    )\n",
    "\n",
    "# The level 1 simulator\n",
    "def sim_level1(x: Input) -> float:\n",
    "    return x[1] + x[0]**2 + x[1]**2 - np.sqrt(2)\n",
    "\n",
    "# The difference between levels 1 and 2\n",
    "def sim_delta(x: Input) -> float:\n",
    "    return sim_func(x) - sim_level1(x)\n",
    "\n",
    "# Package up the level 1 simulator and delta into a single\n",
    "# multi-level object. This makes the following code a bit\n",
    "# nicer.\n",
    "ml_simulator = MultiLevel([sim_level1, sim_delta])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f3eaf4",
   "metadata": {},
   "source": [
    "## Initial design\n",
    "\n",
    "To perform adaptive sampling, we need to begin with a multi-level GP trained with an initial design. We'll adopt the approach taken in\n",
    "[Training a Multi-Level Gaussian Process Emulator](./training_multi_level_gp_tutorial.md),\n",
    "using a Latin hypercube designer [`oneshot_lhs`][exauq.core.designers.oneshot_lhs] (with the aid of [scipy](https://scipy.org/)) for creating\n",
    "the training data for each level of the multi-level GP and defining the multi-level GP\n",
    "to have Matern 5/2 kernel for each level. The full code for doing this is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a5158c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exauq.core.designers import oneshot_lhs\n",
    "from exauq.core.modelling import MultiLevel, TrainingDatum\n",
    "from exauq.core.emulators import MogpEmulator\n",
    "from exauq.core.modelling import MultiLevelGaussianProcess\n",
    "\n",
    "# Create level 1 experimental design of 20 data points\n",
    "lhs_inputs1 = oneshot_lhs(domain, 20, seed=1)\n",
    "\n",
    "# Create level 2 experimental design of 5 data points\n",
    "lhs_inputs2 = oneshot_lhs(domain, 5, seed=1)\n",
    "\n",
    "# Put into a multi-level object\n",
    "design = MultiLevel([lhs_inputs1, lhs_inputs2])\n",
    "\n",
    "# Create outputs for each level (level 2 takes the delta between the two levels)\n",
    "outputs1 = [sim_level1(x) for x in lhs_inputs1]\n",
    "outputs2 = [sim_delta(x) for x in lhs_inputs2]\n",
    "\n",
    "# Create training data\n",
    "initial_data = MultiLevel([\n",
    "    [TrainingDatum(x, y) for x, y in zip(lhs_inputs1, outputs1)],\n",
    "    [TrainingDatum(x, y) for x, y in zip(lhs_inputs2, outputs2)],\n",
    "])\n",
    "\n",
    "# Define multi-level GP\n",
    "gp1 = MogpEmulator(kernel=\"Matern52\")\n",
    "gp2 = MogpEmulator(kernel=\"Matern52\")\n",
    "mlgp = MultiLevelGaussianProcess([gp1, gp2])\n",
    "\n",
    "# Fit to initial data\n",
    "mlgp.fit(initial_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fbc85d-bd80-44bc-9ce2-79eda139a79d",
   "metadata": {},
   "source": [
    "## Extend the design using leave-one-out adaptive sampling (single new point)\n",
    "\n",
    "Let's now find a new design point using the leave-one-out adaptive design methodology for\n",
    "multi-level simulators / GPs. We use the function\n",
    "[`compute_multi_level_loo_samples`][exauq.core.designers.compute_multi_level_loo_samples]\n",
    "to do this. By default, a batch consisting of a single, new design point will be calculated. This function requires three arguments:\n",
    "\n",
    "- The multi-level GP to find the new design point for.\n",
    "- The [`SimulatorDomain`][exauq.core.modelling.SimulatorDomain] describing the domain on\n",
    "  which the simulator is defined.\n",
    "- The relative costs of running the simulator at each level. In our case, this should be\n",
    "  the costs of running the level 1 simulator $f_1$ and the full level 2 simulator\n",
    "  $f$ (not the difference $delta$).\n",
    "\n",
    "Let's suppose for our toy example that the full simulator is 10-times more expensive to\n",
    "run than the level 1 version, so that we assign a cost of 1 to $f_1$ and 10 to $f$.\n",
    "\n",
    "In code, we perform the adaptive sampling as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21059bd1-e419-47f1-b51f-9366c249a0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New design point: (np.float64(0.278133574385051), np.float64(99.99999999896768))\n",
      "Level to run it at: 2\n"
     ]
    }
   ],
   "source": [
    "from exauq.core.designers import compute_multi_level_loo_samples\n",
    "\n",
    "# Suppress warnings that arise from mogp_emulator\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "costs = MultiLevel([1, 10])\n",
    "new_design_pts = compute_multi_level_loo_samples(mlgp, domain, costs)\n",
    "\n",
    "level, new_input = zip(*new_design_pts)\n",
    "\n",
    "print(\"New design point:\", new_input[0])\n",
    "print(\"Level to run it at:\", level[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d356ac",
   "metadata": {},
   "source": [
    "In order to update the fit of the multi-level GP, we need to know which level's GP needs\n",
    "training and the new input point which will be placed on that level. We get this from\n",
    "[`compute_multi_level_loo_samples`][exauq.core.designers.compute_multi_level_loo_samples], \n",
    "which returns a tuple of (level, Input) pairs.\n",
    "\n",
    "We then need to update that level GP with the appropriate training datum. In our case,\n",
    "a level of 1 means we'd need to run the level 1 simulator $f_1$ on the new design point,\n",
    "while a level of 2 means we need to run the **difference** $\\delta$ of the full level 2\n",
    "simulator and the level 1 simulator.\n",
    "\n",
    "If instead we want to compute multiple new design points in one go, we can do this by\n",
    "specifying a different batch size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fda4a52c-b333-4b6b-94b4-45e909b3f6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New design points: (Input(np.float64(0.2781338544801162), np.float64(99.99999999275992)), Input(np.float64(0.999999999894172), np.float64(25.54540183550317)), Input(np.float64(-0.9999999999367358), np.float64(73.34241659146552)), Input(np.float64(-0.08218041195830439), np.float64(61.924868615863666)), Input(np.float64(0.6646936114256603), np.float64(99.99999999733132)))\n",
      "Level to run batch at: (2, 2, 2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "new_design_pts = compute_multi_level_loo_samples(mlgp, domain, costs, batch_size=5)\n",
    "\n",
    "levels, new_inputs = zip(*new_design_pts)\n",
    "\n",
    "print(\"New design points:\", new_inputs)\n",
    "print(\"Level to update design point at:\", levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4dfa10",
   "metadata": {},
   "source": [
    "## Update the multi-level GP\n",
    "\n",
    "The final step is to update the fit of the multi-level GP using the newly-calculated\n",
    "design points and the given level. This first requires us to compute the correct simulator\n",
    "outputs at the design points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98b05590",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_outputs = [ml_simulator[level](x) for level, x in new_design_pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330022ae",
   "metadata": {},
   "source": [
    "To update the multi-level GP, we can then use the update method of mlgp by passing new design points generated from [`compute_multi_level_loo_samples`][exauq.core.designers.compute_multi_level_loo_samples] and the relevant outputs.\n",
    "\n",
    "Note: You **must** pass the design points from [`compute_multi_level_loo_samples`][exauq.core.designers.compute_multi_level_loo_samples], because each design point has the corresponding level of GP attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a83fa641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data at each level: {1: 20, 2: 10}\n"
     ]
    }
   ],
   "source": [
    "mlgp.update(new_design_pts, new_outputs)\n",
    "\n",
    "# Sense-check that the GP at the level has been updated\n",
    "print(\n",
    "    \"Number of training data at each level:\",\n",
    "    {level: len(mlgp[level].training_data) for level in mlgp.levels}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741c8aa6",
   "metadata": {},
   "source": [
    "This completes one adaptive sampling 'iteration'. It's important to note that, when\n",
    "creating a batch of multiple new design points, the fit of the GP is not updated between\n",
    "the creation of each new point in the batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9121e9a9",
   "metadata": {},
   "source": [
    "## Repeated application\n",
    "\n",
    "In general, we can perform multiple adaptive sampling iterations to further improve the\n",
    "fit of the multi-level GP with newly sampled design point(s). The following code goes\n",
    "through five more sampling iterations, producing a single new design point at each\n",
    "iteration. We have also introduced a helper function to assist in retraining the\n",
    "multi-level GP. (Once again, the messages from the `mogp_emulator` package can be\n",
    "ignored.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2457caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Updated level 2 with new design point (np.float64(0.9999999999257614), np.float64(75.33364367061057))\n",
      "==> Updated level 2 with new design point (np.float64(-0.5882054699841657), np.float64(99.99999999707114))\n",
      "==> Updated level 2 with new design point (np.float64(0.9999999805155508), np.float64(45.67471343491659))\n",
      "==> Updated level 2 with new design point (np.float64(-0.559556487257387), np.float64(68.22417412540355))\n",
      "==> Updated level 2 with new design point (np.float64(0.12749382990259406), np.float64(80.23935864354945))\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    # Find new design point adaptively (via batch of length 1)\n",
    "    new_design_pts = compute_multi_level_loo_samples(mlgp, domain, costs)\n",
    "    level, new_input = zip(*new_design_pts)\n",
    "\n",
    "    x = new_input[0]\n",
    "    lvl = level[0]\n",
    "\n",
    "    # Compute simulator output at new design point\n",
    "    new_output = ml_simulator[lvl](x)\n",
    "\n",
    "    # Update GP fit (Note passing output as a list)\n",
    "    mlgp.update(new_design_pts, [new_output])\n",
    "\n",
    "    # Print design point found and level applied at\n",
    "    print(f\"==> Updated level {lvl} with new design point {x}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exauq-U32eSCBI-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
